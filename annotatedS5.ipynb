{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The Annotated S5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Welcome! In this tutorial we will be implementing the Simplified Structured State for Sequence Modeling (phew!), or more simply, S5, in Deepmind's Haiku neural network library for JAX. I've chosen to highlight the S5 because, though building off the original S4 and its variations, DSS, S4D, Liquid-S4 etc., as the extra S suggests, it provides a nice simplification of this family of architectures. If you are unfamiliar with any of these previous models I highly recommend checking out Sasha Rush's excellent blog post on the subject: https://srush.github.io/annotated-s4/, and its corresponding repository: https://github.com/srush/annotated-s4, in which he implements the original S4 in Flax. These were both extremely helpful for me in learning to understand and implement these architectures and serves as the direct inspiration for this notebook, so please do check them out! However, I've tried to make the notebook as self-contained and accessible as possible so if you feel like jumping straight in, feel free. I should also mention the original repository from the paper authors: https://github.com/lindermanlab/S5, which itself was highly based after Sasha Rush's Flax implementation of the S4s and has been the main guide for my implementation, I have chosen to write mine in Haiku rather than Flax simply because that is my personal framework of choice for building from scratch implementations of any models I study, so if you are unfamiliar with Haiku hopefully this can serve as a little introduction to that as well!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First I will briefly address what has been seen by many to be the black box of this family of architectures, and that is the High-order Polynomial Projection Operators, or HiPPOs, this is a new recurrent memory mechanism first introduced in https://arxiv.org/abs/2008.07669 that replaces the standard memory unit found in GRUs and LSTMSs with an online function approximation based on a series of orthogonal polynomials, thereby creating an internal representation/memory of the function being modeled. Gu et al. gives a short comparison to standard RNN memory units in the paper above as follows:\n",
    "\n",
    "    \"As a special case, we consider what happens if we do not incorporate higher-order polynomials in the projection problem. Specifically, if N = 1, then the discretized version of HiPPO-LagT (2) becomes c(t + ∆t) = c(t) + ∆t(−Ac(t) + Bf(t)) = (1 − ∆t)c(t) + ∆tf(t), since A = B = 1. If the inputs f(t) can depend on the hidden state c(t) and the discretization step size ∆t is chosen adaptively (as a function of input f(t) and state c(t)), as in RNNs, then this becomes exactly a gated RNN. For instance, by stacking multiple units in parallel and choosing a specific update function, we obtain the GRU update cell as a special case. In contrast to HiPPO which uses one hidden feature and projects it onto high order polynomials, these models use many hidden features but only project them with degree 1. This view sheds light on these classic techniques by showing how they can be derived from first principles.\"\n",
    "\n",
    "There's alot of fascinating components that go into these memory structures which I plan to write a whole other post about, but for now I will leave it at the short description above and note that we will be initializing our HiPPOs with a little library called Hippox which I created for that very purpose, check out the source code if you feel like diving a bit deeper: https://github.com/JPGoodale/hippox (shameless self-promotion), and of course I highly recommend reading the original papers and their code: https://github.com/HazyResearch/state-spaces."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Let's go ahead and import hippox and the core JAX libraries we will be using\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "from hippox.main import Hippo\n",
    "from typing import Optional"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we'll define some helper functions for discretization and timescale initialization as the SSM equation is naturally continuous and must be made discrete to be unrolled as a linear recurrence like standard RNNs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Here we are just using the zero order hold method for its sheer simplicity, with A, B and delta_t denoting the state matrix, input matrix and change in timescale respectively\n",
    "def discretize(A, B, delta_t):\n",
    "    _A = jnp.exp(delta_t*A)\n",
    "    _B = (jnp.exp(delta_t*A)-1) / A*B\n",
    "    return _A, _B\n",
    "\n",
    "# This is function used to initialize the trainable timescale parameter\n",
    "def log_step_initializer(dt_min=0.001, dt_max=0.1):\n",
    "    def init(shape, dtype):\n",
    "        uniform = hk.initializers.RandomUniform()\n",
    "        return uniform(shape, dtype)*(jnp.log(dt_max) - jnp.log(dt_min)) + jnp.log(dt_min)\n",
    "    return init\n",
    "\n",
    "# Taken directly from Haiku._src.recurrent\n",
    "def add_batch(nest, batch_size: Optional[int]):\n",
    "    broadcast = lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape)\n",
    "    return jax.tree_util.tree_map(broadcast, nest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we'll give a simple demonstration of the core structure of linear State Space Models as a Haiku module:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LinearSSM(hk.RNNCore):\n",
    "    def __init__(self, state_size: int, name: Optional[str] = None):\n",
    "        super(LinearSSM, self).__init__(name=name)\n",
    "        # We won't get into the basis measure families here, just note that they are basically just what type of orthogonal\n",
    "        # polynomial we initialize with, the scaled Legendre measure (LegS) introduced in the original HiPPO paper is pretty\n",
    "        # much the standard initialization and is what is used in all experiments in the S5 paper. I will also note the Hippo\n",
    "        # class uses the diagonal representation of the state matrix by default as this has become the standard in neural SSMs\n",
    "        # since shown to be equally effective as the diagonal plus low rank representation in https://arxiv.org/abs/2203.14343\n",
    "        # and then formalized in https://arxiv.org/abs/2206.11893, once again I encourage you to read through these papers and\n",
    "        # follow the fascinating journey of these special matrices being continually simplified and made more and more memory efficient.\n",
    "\n",
    "        _hippo = Hippo(state_size=state_size, measure_family='legs')\n",
    "        # Must be called for parameters to be initialized\n",
    "        _hippo()\n",
    "\n",
    "        # We register the real and imaginary components of the state matrix A as separate parameters because they will have\n",
    "        # separate gradients in training, they will be conjoined back together and then discretized but this will simply be\n",
    "        # backpropagated through as a transformation of the lambda real and imaginary parameters. (lambda is just what we call\n",
    "        # the diagonalized state matrix)\n",
    "\n",
    "        self._lambda_real = hk.get_parameter(\n",
    "            'lambda_real',\n",
    "            shape=[state_size,],\n",
    "            init=_hippo.lambda_initializer('real')\n",
    "        )\n",
    "        self._lambda_imag = hk.get_parameter(\n",
    "            'lambda_imaginary',\n",
    "            shape=[state_size,],\n",
    "            init=_hippo.lambda_initializer('imaginary')\n",
    "        )\n",
    "        self._A = self._lambda_real + 1j * self._lambda_imag\n",
    "\n",
    "       # These initializations of the input and output matrices B and C for right now match the S4D\n",
    "        # parameterization for demonstration purposes, we will implement the S5 versions instead later.\n",
    "\n",
    "        self._B = hk.get_parameter(\n",
    "            'B',\n",
    "            shape=[state_size,],\n",
    "            init=_hippo.b_initializer()\n",
    "        )\n",
    "        self._C = hk.get_parameter(\n",
    "            'C',\n",
    "            shape=[state_size, 2],\n",
    "            init=hk.initializers.RandomNormal(stddev=0.5**0.5)\n",
    "        )\n",
    "        self._output_matrix = self._C[..., 0] + 1j * self._C[..., 1]\n",
    "\n",
    "        # This parameter basically acts as a residual connection on the input\n",
    "        self._D = hk.get_parameter(\n",
    "            'D',\n",
    "            [1,],\n",
    "            init=jnp.ones,\n",
    "        )\n",
    "\n",
    "        self._delta_t = hk.get_parameter(\n",
    "            'delta_t',\n",
    "            shape=[1,],\n",
    "            init=log_step_initializer()\n",
    "        )\n",
    "        timescale = jnp.exp(self._delta_t)\n",
    "\n",
    "        self._state_matrix, self._input_matrix = discretize(self._A, self._B, timescale)\n",
    "\n",
    "    def __call__(self, inputs, prev_state):\n",
    "        u = inputs[:, jnp.newaxis]\n",
    "        new_state = self._state_matrix @ prev_state + self._input_matrix @ u\n",
    "        y_s = self._output_matrix @ new_state\n",
    "        out = y_s.reshape(-1).real + self._D * u\n",
    "        return out, new_state\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int] = None):\n",
    "        state = jnp.zeros([self._state_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may notice that this looks an awful lot like a vanilla RNN cell, just with our special parameterization and without any activations, hence being a linear recurrence. I have initialized it as an instance of Haiku's RNN.Core abstract base class so that it can be unrolled using either the hk.dynamic_unroll or hk.static_unroll functions like any other recurrent module, however if you've studied any of the S4 models you may be noticing that there's something crucial missing here: the convolutional representation. One of the key contributions of the S4 paper was its demonstration that the SSM ODE can be represented as either a linear recurrence, as above, for efficient inference or as a global convolution for much faster training. That paper and the following papers then go on to present various complex kernels for efficiently computing this convolution with Fast Fourier Transforms, highly improving the computational efficiency of the model. Then why have we omitted these? Because the S5 architecture which we are about to explore simplifies all this by providing a purely recurrent representation in both training and inference using a parallel recurrence that actually looks alot like a convolution itself! From the paper:\n",
    "\n",
    "    \"We use parallel scans to efficiently compute the states of a discretized linear SSM. Given a binary associative operator • (i.e. (a • b) • c = a • (b • c)) and a sequence of L elements [a1, a2, ..., aL], the scan operation (sometimes referred to as all-prefix-sum) returns the sequence [a1, (a1 • a2), ..., (a1 • a2 • ... • aL)].\"\n",
    "\n",
    "Let's see what this looks like in code, taken straight from the original author's implementation:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def binary_operator(q_i, q_j):\n",
    "    A_i, b_i = q_i\n",
    "    A_j, b_j = q_j\n",
    "    return A_j * A_i, A_j * b_i + b_j\n",
    "\n",
    "def parallel_scan(A, B, C, inputs):\n",
    "    A_elements = A * jnp.ones((inputs.shape[0], A.shape[0]))\n",
    "    Bu_elements = jax.vmap(lambda u: B @ u)(inputs)\n",
    "    # Jax's built-in associative scan really comes in handy here as it executes the same scan used in our standard recurrent\n",
    "    # unrolls like hk.dynamic_unroll but is specifically tailored to fit an associative operation like the one defined above.\n",
    "    _, xs = jax.lax.associative_scan(binary_operator, (A_elements, Bu_elements))\n",
    "    return jax.vmap(lambda x: (C @ x).real)(xs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's that simple! By using this technique we have also transformed our SSM from a single-input, single-output (SISO) cell to a multi-input, multi-output (MIMO) one, hence the use of JAX's vmap function right in our \"unroll\" rather than at a higher level over the whole SSM block as in the S4. Let's now rewrite our Module as a full S5 layer using this new method, we will be adding a few extra conditional arguments as well as changing some parameterization to match the original paper, but we'll walk through the reason for all these changes below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# First we add a new helper function for the timescale initialization, this one just takes the previous\n",
    "# log_step_initializer and stores a bunch of them in an array since our model is now multi-in, multi-out\n",
    "\n",
    "def init_log_steps(shape, dtype):\n",
    "    H = shape[0]\n",
    "    log_steps = []\n",
    "    for i in range(H):\n",
    "        log_step = log_step_initializer()(shape=(1,), dtype=dtype)\n",
    "        log_steps.append(log_step)\n",
    "\n",
    "    return jnp.array(log_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# We will also rewrite our discretization for the MIMO new setting\n",
    "def discretize(A, B, delta_t):\n",
    "    Identity = jnp.ones(A.shape[0])\n",
    "    _A = jnp.exp(A*delta_t)\n",
    "    _B = (1/A * (_A-Identity))[..., None] * B\n",
    "    return _A, _B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class S5(hk.Module):\n",
    "    def __init__(self,\n",
    "                 state_size: int,\n",
    "                 # Now that we're MIMO we'll need to know the number of input features, commonly referred to as the dimension of the model\n",
    "                 d_model: int,\n",
    "                 # We must also now specify the number of blocks that we will split our matrices into due to the MIMO setting\n",
    "                 n_blocks: int,\n",
    "                 # Short for conjugate symmetry, because our state matrix is complex we can half the size of it since complex numbers\n",
    "                 # are a real and imaginary number joined together, this is not new to the S5 we just didn't mention it above for simplicity\n",
    "                 conj_sym: bool = True,\n",
    "                 # Another standard SSM argument that we omitted above for simplicity's sake, this forces the real part of the state matrix\n",
    "                 # to be negative for better stability, especially in autoregressive tasks\n",
    "                 clip_eigns: bool = False,\n",
    "                 # Like most RNNs the S5 can be \"unrolled\" in both directions if need be\n",
    "                 bidirectional: bool = False,\n",
    "                 # Rescales delta_t for varying input resolutions, such as different audio sampling rates\n",
    "                 step_rescale: float = 1.0,\n",
    "                 name: Optional[str] = None\n",
    "    ):\n",
    "        super(S5, self).__init__(name=name)\n",
    "        self.conj_sym = conj_sym\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Note that the Hippo class takes conj_sym as an argument and will automatically half the state size provided in its initialization,\n",
    "        # which is why we need to provide a local state size that matches this for the shape argument in hk.get_parameter()\n",
    "\n",
    "        if conj_sym:\n",
    "            _state_size = state_size // 2\n",
    "        else:\n",
    "            _state_size = state_size\n",
    "\n",
    "        # With block_diagonal set as True and the number of blocks provided, our Hippo class will automatically handle this change of structure\n",
    "\n",
    "        _hippo = Hippo(\n",
    "            state_size=state_size,\n",
    "            measure_family='legs',\n",
    "            conj_sym=conj_sym,\n",
    "            block_diagonal=True,\n",
    "            n_blocks=n_blocks,\n",
    "        )\n",
    "        _hippo()\n",
    "\n",
    "        self._lambda_real = hk.get_parameter(\n",
    "            'lambda_real',\n",
    "            [_state_size],\n",
    "            init=_hippo.lambda_initializer('real')\n",
    "        )\n",
    "        self._lambda_imag = hk.get_parameter(\n",
    "            'lambda_imaginary',\n",
    "            [_state_size],\n",
    "            init=_hippo.lambda_initializer('imaginary')\n",
    "        )\n",
    "        if clip_eigns:\n",
    "            self._lambda = jnp.clip(self._lambda_real, None, -1e-4) + 1j * self._lambda_imag\n",
    "        else:\n",
    "            self._A = self._lambda_real + 1j * self._lambda_imag\n",
    "\n",
    "        # If you recall, I mentioned above that we are automatically using a diagonalized version of the HiPPO state matrix\n",
    "        # \\rather than the pure one, due to it being very hard to efficiently compute. I will now go into a little more detail\n",
    "        # on how this diagonal representation is derived, as it is important for how we initialize the input and output matrices\n",
    "        # here. The diagonal decomposition of our state matrix is based on equivalence relation on the SSM parameters: (A, B, C)\n",
    "        # ∼ (V−1AV ,V−1B, CV) with V being the eigenvector of our original A matrix and V-1 being the inverse eigenvector. The Hippo\n",
    "        # class has already performed the decomposition of A into (V-1AV) automatically, but we have not yet performed the decomposition\n",
    "        # of B and C, we will use the eigenvector_transform class method for that below, but first we must initialize B and C as normal\n",
    "        # distributions, lecun normal and truncated normal respectively. I will note that there are a few other options provided for C in\n",
    "        # the original repository but to keep it simple we will just use one here.\n",
    "\n",
    "        b_init = hk.initializers.VarianceScaling()\n",
    "        b_shape = [state_size, d_model]\n",
    "        b_init = b_init(b_shape, dtype=jnp.complex64)\n",
    "        self._B = hk.get_parameter(\n",
    "            'B',\n",
    "            [_state_size, d_model, 2],\n",
    "            init=_hippo.eigenvector_transform(b_init,  concatenate=True),\n",
    "        )\n",
    "        B = self._B[..., 0] + 1j * self._B[..., 1]\n",
    "\n",
    "        c_init = hk.initializers.TruncatedNormal()\n",
    "        c_shape = [d_model, state_size, 2]\n",
    "        c_init = c_init(c_shape, dtype=jnp.complex64)\n",
    "        self._C = hk.get_parameter(\n",
    "            'C',\n",
    "            [d_model, _state_size, 2],\n",
    "            init=_hippo.eigenvector_transform(c_init, inverse=False, concatenate=True),\n",
    "        )\n",
    "        # We need two output heads if bidirectional\n",
    "        if bidirectional:\n",
    "            self._C2 = hk.get_parameter(\n",
    "                'C2',\n",
    "                [d_model, _state_size, 2],\n",
    "                init=_hippo.eigenvector_transform(c_init, inverse=False, concatenate=True),\n",
    "            )\n",
    "            C1 = self._C[..., 0] + 1j * self._C[..., 1]\n",
    "            C2 = self._C2[..., 0] + 1j * self._C2[..., 1]\n",
    "            self._output_matrix = jnp.concatenate((C1, C2), axis=-1)\n",
    "        else:\n",
    "            self._output_matrix = self._C[..., 0] + 1j * self._C[..., 1]\n",
    "\n",
    "        self._D = hk.get_parameter(\n",
    "            'D',\n",
    "            [d_model,],\n",
    "            init=hk.initializers.RandomNormal(stddev=1.0)\n",
    "        )\n",
    "\n",
    "        self._delta_t = hk.get_parameter(\n",
    "            'delta_T',\n",
    "            [_state_size, 1],\n",
    "            init=init_log_steps\n",
    "        )\n",
    "        timescale = step_rescale * jnp.exp(self._delta_t[:, 0])\n",
    "\n",
    "        # We could also use the bilinear discretization method, but we'll just stick to zoh for now.\n",
    "        self._state_matrix, self._input_matrix = discretize(self._A, B, timescale)\n",
    "\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Note that this is the exact same function as presented above just with alternate procedures\n",
    "        # depending on the bidirectional and conjugate symmetry arguments\n",
    "\n",
    "        A_elements = self._state_matrix * jnp.ones((inputs.shape[0], self._state_matrix.shape[0]))\n",
    "        Bu_elements = jax.vmap(lambda u: self._input_matrix @ u)(inputs)\n",
    "\n",
    "        _, xs = jax.lax.associative_scan(binary_operator, (A_elements, Bu_elements))\n",
    "\n",
    "        if self.bidirectional:\n",
    "            _, xs2 = jax.lax.associative_scan(binary_operator,\n",
    "                                          (A_elements, Bu_elements),\n",
    "                                          reverse=True)\n",
    "            xs = jnp.concatenate((xs, xs2), axis=-1)\n",
    "\n",
    "        if self.conj_sym:\n",
    "            ys = jax.vmap(lambda x: 2*(self._output_matrix @ x).real)(xs)\n",
    "        else:\n",
    "            ys = jax.vmap(lambda x: (self._output_matrix @ x).real)(xs)\n",
    "\n",
    "        Du = jax.vmap(lambda u: self._D * u)(inputs)\n",
    "\n",
    "        return ys + Du"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There we have it, a complete S5 layer! We'll now form a block around it using a structure very similar to a transformer block with a gated linear unit (glu)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class S5Block(hk.Module):\n",
    "    ssm: S5\n",
    "    d_model: int\n",
    "    dropout_rate: float\n",
    "    prenorm: bool\n",
    "    istraining: bool = True\n",
    "    name: Optional[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super(S5Block, self).__post_init__()\n",
    "        # We could use either layer norm or batch norm, I just chose layer norm here for simplicity\n",
    "        self._norm = hk.LayerNorm(axis=-1, create_scale=True, create_offset=True)\n",
    "        self._linear = hk.Linear(self.d_model)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        skip = x\n",
    "        if self.prenorm:\n",
    "            x = self._norm(x)\n",
    "\n",
    "        x = self.ssm(x)\n",
    "        # There are a couple of other glu patterns we could use here but once again I have chosen\n",
    "        # semi-arbitrarily to avoid cluttering our module with if statements\n",
    "        x1 = hk.dropout(hk.next_rng_key(), self.dropout_rate, jax.nn.gelu(x))\n",
    "        x = x * jax.nn.sigmoid(self._linear(x1))\n",
    "        x = hk.dropout(hk.next_rng_key(), self.dropout_rate, x)\n",
    "\n",
    "        x = skip + x\n",
    "        if not self.prenorm:\n",
    "            x = self._norm(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's make a stack of these blocks:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class S5Stack(hk.Module):\n",
    "    ssm: S5\n",
    "    d_model: int\n",
    "    n_layers: int\n",
    "    dropout_rate: float\n",
    "    prenorm: bool\n",
    "    istraining: bool = True\n",
    "    name: Optional[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super(S5Stack, self).__post_init__(name=self.name)\n",
    "        self._encoder = hk.Linear(self.d_model)\n",
    "        self._layers = [\n",
    "            S5Block(\n",
    "                ssm=self.ssm,\n",
    "                d_model=self.d_model,\n",
    "                dropout_rate=self.dropout_rate,\n",
    "                istraining=self.istraining,\n",
    "                prenorm=self.prenorm,\n",
    "            )\n",
    "            for _ in range(self.n_layers)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self._encoder(x)\n",
    "        for layer in self._layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And finally a classification layer on top:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class S5Classifier(hk.Module):\n",
    "    ssm: S5\n",
    "    d_model: int\n",
    "    d_output: int\n",
    "    n_layers: int\n",
    "    dropout_rate: float\n",
    "    mode: str = 'pool'\n",
    "    prenorm: bool = True\n",
    "    istraining: bool = True\n",
    "    name: Optional[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super(S5Classifier, self).__post_init__(name=self.name)\n",
    "        self._encoder = S5Stack(\n",
    "            ssm=self.ssm,\n",
    "            d_model=self.d_model,\n",
    "            n_layers=self.n_layers,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            istraining=self.istraining,\n",
    "            prenorm=self.prenorm,\n",
    "        )\n",
    "        self._decoder = hk.Linear(self.d_output)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self._encoder(x)\n",
    "        if self.mode == 'pool':\n",
    "            x = jnp.mean(x, axis=0)\n",
    "        elif self.mode == 'last':\n",
    "            x = x[-1]\n",
    "        else:\n",
    "            raise NotImplementedError(\"Mode must be in ['pool', 'last]\")\n",
    "        x = self._decoder(x)\n",
    "        return jax.nn.log_softmax(x, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our model is now ready for training! Let's load some data. I will be doing a simple cifar10 classification task, but unlike the standard CNNs used for the task, we will be processing the images as a 1-dimensional sequence."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import NamedTuple\n",
    "\n",
    "# Code taken directly from https://github.com/srush/annotated-s4\n",
    "def create_cifar_classification_dataset(batch_size=128):\n",
    "    print(\"[*] Generating CIFAR-10 Classification Dataset\")\n",
    "\n",
    "    # Here we flatten the 32*32 images into a sequence length of 784\n",
    "    SEQ_LENGTH, N_CLASSES, IN_DIM = 32 * 32, 10, 3\n",
    "    tf = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "            ),\n",
    "            transforms.Lambda(lambda x: x.view(IN_DIM, SEQ_LENGTH).t()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train = torchvision.datasets.CIFAR10(\n",
    "        \"./data\", train=True, download=True, transform=tf\n",
    "    )\n",
    "    test = torchvision.datasets.CIFAR10(\n",
    "        \"./data\", train=False, download=True, transform=tf\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        train, batch_size, shuffle=True\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        test, batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader, N_CLASSES, SEQ_LENGTH, IN_DIM\n",
    "\n",
    "\n",
    "Datasets = {\n",
    "    \"cifar-classification\": create_cifar_classification_dataset,\n",
    "}\n",
    "\n",
    "# Simple class for storing our dataset parameters\n",
    "class Dataset(NamedTuple):\n",
    "    trainloader: DataLoader\n",
    "    testloader: DataLoader\n",
    "    n_classes: int\n",
    "    seq_length: int\n",
    "    d_input: int\n",
    "    classification: bool\n",
    "\n",
    "def create_dataset(dataset: str, batch_size: int) -> Dataset:\n",
    "    classification = 'classification' in dataset\n",
    "    dataset_init = Datasets[dataset]\n",
    "    trainloader, testloader, n_classes, seq_length, d_input = dataset_init(batch_size)\n",
    "    return Dataset(trainloader, testloader, n_classes, seq_length, d_input, classification)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we will set some hyperparameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "STATE_SIZE: int = 128\n",
    "D_MODEL: int = 64\n",
    "N_LAYERS: int = 6\n",
    "N_BLOCKS: int = 8\n",
    "EPOCHS: int = 100\n",
    "BATCH_SIZE: int = 128\n",
    "DROPOUT_RATE: float = 0.5\n",
    "LEARNING_RATE: float = 0.005\n",
    "SEED = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this example, we will just be using a plain adam optimizer, but the results can be highly improved with extra techniques such as cosine annealing, learning rate schedules and weight decay."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "    params: hk.Params\n",
    "    opt_state: optax.OptState\n",
    "    rng_key: jnp.ndarray\n",
    "\n",
    "optim = optax.adam(LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for the loss and update functions:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Tuple, MutableMapping, Any\n",
    "_Metrics = MutableMapping[str, Any]\n",
    "\n",
    "@partial(jnp.vectorize, signature=\"(c),()->()\")\n",
    "def cross_entropy_loss(logits, label) -> jnp.ndarray:\n",
    "    one_hot_label = jax.nn.one_hot(label, num_classes=logits.shape[0])\n",
    "    return -jnp.sum(one_hot_label * logits)\n",
    "\n",
    "\n",
    "@partial(jnp.vectorize, signature=\"(c),()->()\")\n",
    "def compute_accuracy(logits, label):\n",
    "    return jnp.argmax(logits) == label\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3, 4))\n",
    "def update(\n",
    "        state: TrainingState,\n",
    "        inputs: jnp.ndarray,\n",
    "        targets: jnp.ndarray,\n",
    "        model: hk.transform,\n",
    "        classification: bool = False\n",
    ") -> Tuple[TrainingState, _Metrics]:\n",
    "\n",
    "    rng_key, next_rng_key = jax.random.split(state.rng_key)\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = model.apply(params, rng_key, inputs)\n",
    "        _loss = jnp.mean(cross_entropy_loss(logits, targets))\n",
    "        _accuracy = jnp.mean(compute_accuracy(logits, targets))\n",
    "        return _loss, _accuracy\n",
    "\n",
    "    if not classification:\n",
    "        targets = inputs[:, :, 0]\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, accuracy), gradients = grad_fn(state.params)\n",
    "    updates, new_opt_state = optim.update(gradients, state.opt_state, state.params)\n",
    "    new_params = optax.apply_updates(state.params, updates)\n",
    "\n",
    "    new_state = TrainingState(\n",
    "        params=new_params,\n",
    "        opt_state=new_opt_state,\n",
    "        rng_key=next_rng_key,\n",
    "    )\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    return new_state, metrics\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3, 4))\n",
    "def evaluate(\n",
    "        state: TrainingState,\n",
    "        inputs: jnp.ndarray,\n",
    "        targets: jnp.ndarray,\n",
    "        model: hk.transform,\n",
    "        classification: bool = False\n",
    ") -> _Metrics:\n",
    "\n",
    "    rng_key, _ = jax.random.split(state.rng_key, 2)\n",
    "\n",
    "    if not classification:\n",
    "        targets = inputs[:, :, 0]\n",
    "\n",
    "    logits = model.apply(state.params, rng_key, inputs)\n",
    "    loss = jnp.mean(cross_entropy_loss(logits, targets))\n",
    "    accuracy = jnp.mean(compute_accuracy(logits, targets))\n",
    "\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now we call these update and evaluate functions in their respective epochs:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def training_epoch(\n",
    "        state: TrainingState,\n",
    "        trainloader: DataLoader,\n",
    "        model: hk.transform,\n",
    "        classification: bool = False,\n",
    ") -> Tuple[TrainingState, jnp.ndarray, jnp.ndarray]:\n",
    "\n",
    "    batch_losses, batch_accuracies = [], []\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "        inputs = jnp.array(inputs.numpy())\n",
    "        targets = jnp.array(targets.numpy())\n",
    "        state, metrics = update(\n",
    "            state, inputs, targets,\n",
    "            model, classification\n",
    "        )\n",
    "        batch_losses.append(metrics['loss'])\n",
    "        batch_accuracies.append(metrics['accuracy'])\n",
    "\n",
    "    return (\n",
    "        state,\n",
    "        jnp.mean(jnp.array(batch_losses)),\n",
    "        jnp.mean(jnp.array(batch_accuracies))\n",
    "    )\n",
    "\n",
    "\n",
    "def validation_epoch(\n",
    "        state: TrainingState,\n",
    "        testloader: DataLoader,\n",
    "        model: hk.transform,\n",
    "        classification: bool = True,\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "\n",
    "    losses, accuracies = [], []\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(testloader)):\n",
    "        inputs = jnp.array(inputs.numpy())\n",
    "        targets = jnp.array(targets.numpy())\n",
    "        metrics = evaluate(\n",
    "            state, inputs, targets,\n",
    "            model, classification\n",
    "        )\n",
    "        losses.append(metrics['loss'])\n",
    "        accuracies.append(metrics['accuracy'])\n",
    "\n",
    "    return jnp.mean(jnp.array(losses)), jnp.mean(jnp.array(accuracies))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import torch\n",
    "# Set random number generators\n",
    "torch.random.manual_seed(SEED)\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "key, rng, train_rng = jax.random.split(key, num=3)\n",
    "rng, init_rng = jax.random.split(rng)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating CIFAR-10 Classification Dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create our dataset and dummy data for initialization of model's params\n",
    "ds = create_dataset('cifar-classification', BATCH_SIZE)\n",
    "init_data = jnp.array(next(iter(ds.trainloader))[0].numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# In Haiku, we have to call our model inside a transformed function using hk.transform for it to become\n",
    "# functionally pure and compatible with essential JAX transforms like jax.grad(). Here we are using hk.vmap\n",
    "# instead of jax.vmap because we are calling it from with a hk.transform.\n",
    "@hk.transform\n",
    "def forward(x) -> hk.transform:\n",
    "    neural_net = S5Classifier(\n",
    "        S5(\n",
    "            STATE_SIZE,\n",
    "            D_MODEL,\n",
    "            N_BLOCKS,\n",
    "        ),\n",
    "        D_MODEL,\n",
    "        ds.n_classes,\n",
    "        N_LAYERS,\n",
    "        DROPOUT_RATE,\n",
    "    )\n",
    "    return hk.vmap(neural_net, split_rng=False)(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpgoodale/anaconda3/envs/dl/lib/python3.10/site-packages/jax/_src/lax/lax.py:558: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return _convert_element_type(operand, new_dtype, weak_type=False)\n"
     ]
    }
   ],
   "source": [
    "# Set state\n",
    "initial_params = forward.init(init_rng, init_data)\n",
    "initial_opt_state = optim.init(initial_params)\n",
    "\n",
    "state = TrainingState(\n",
    "    params=initial_params,\n",
    "    opt_state=initial_opt_state,\n",
    "    rng_key=rng\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And finally our training loop!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training Epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 391/391 [01:24<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Running Epoch 1 Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 79/79 [00:09<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>> Epoch 1 Metrics ===\n",
      "\tTrain Loss: 1.88568 -- Train Accuracy: 0.3549\n",
      "\t Test Loss: 1.57461 --  Test Accuracy: 0.4325\n",
      "[*] Training Epoch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 391/391 [01:05<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Running Epoch 2 Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>> Epoch 2 Metrics ===\n",
      "\tTrain Loss: 1.54669 -- Train Accuracy: 0.4395\n",
      "\t Test Loss: 1.50880 --  Test Accuracy: 0.4560\n",
      "[*] Training Epoch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 391/391 [01:07<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Running Epoch 3 Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>> Epoch 3 Metrics ===\n",
      "\tTrain Loss: 1.46129 -- Train Accuracy: 0.4706\n",
      "\t Test Loss: 1.43100 --  Test Accuracy: 0.4841\n",
      "[*] Training Epoch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 391/391 [01:08<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Running Epoch 4 Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>> Epoch 4 Metrics ===\n",
      "\tTrain Loss: 1.39461 -- Train Accuracy: 0.4939\n",
      "\t Test Loss: 1.42680 --  Test Accuracy: 0.4866\n",
      "[*] Training Epoch 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 391/391 [01:10<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Running Epoch 5 Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>> Epoch 5 Metrics ===\n",
      "\tTrain Loss: 1.35123 -- Train Accuracy: 0.5130\n",
      "\t Test Loss: 1.36369 --  Test Accuracy: 0.5060\n",
      "[*] Training Epoch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████▊                                          | 137/391 [00:24<00:45,  5.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [46]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCHS):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[*] Training Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m     state, training_loss, training_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassification\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[*] Running Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Validation...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m     test_loss, test_accuracy \u001B[38;5;241m=\u001B[39m validation_epoch(\n\u001B[1;32m     11\u001B[0m         state,\n\u001B[1;32m     12\u001B[0m         ds\u001B[38;5;241m.\u001B[39mtestloader,\n\u001B[1;32m     13\u001B[0m         forward,\n\u001B[1;32m     14\u001B[0m         ds\u001B[38;5;241m.\u001B[39mclassification\n\u001B[1;32m     15\u001B[0m     )\n",
      "Input \u001B[0;32mIn [41]\u001B[0m, in \u001B[0;36mtraining_epoch\u001B[0;34m(state, trainloader, model, classification)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtraining_epoch\u001B[39m(\n\u001B[1;32m      4\u001B[0m         state: TrainingState,\n\u001B[1;32m      5\u001B[0m         trainloader: DataLoader,\n\u001B[1;32m      6\u001B[0m         model: hk\u001B[38;5;241m.\u001B[39mtransform,\n\u001B[1;32m      7\u001B[0m         classification: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      8\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[TrainingState, jnp\u001B[38;5;241m.\u001B[39mndarray, jnp\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m     10\u001B[0m     batch_losses, batch_accuracies \u001B[38;5;241m=\u001B[39m [], []\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (inputs, targets) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(trainloader)):\n\u001B[1;32m     12\u001B[0m         inputs \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39marray(inputs\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     13\u001B[0m         targets \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39marray(targets\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/datasets/cifar.py:118\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    115\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    121\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/transforms.py:94\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m---> 94\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/transforms.py:134\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    127\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/transforms/functional.py:164\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;66;03m# handle PIL Image\u001B[39;00m\n\u001B[1;32m    163\u001B[0m mode_to_nptype \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint32, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint16, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mfloat32}\n\u001B[0;32m--> 164\u001B[0m img \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_to_nptype\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    167\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m img\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/PIL/Image.py:678\u001B[0m, in \u001B[0;36mImage.__array_interface__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    674\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array_interface__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;66;03m# numpy array interface support\u001B[39;00m\n\u001B[1;32m    677\u001B[0m     new \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 678\u001B[0m     shape, typestr \u001B[38;5;241m=\u001B[39m \u001B[43m_conv_type_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    679\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m shape\n\u001B[1;32m    680\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtypestr\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m typestr\n",
      "File \u001B[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/PIL/Image.py:241\u001B[0m, in \u001B[0;36m_conv_type_shape\u001B[0;34m(im)\u001B[0m\n\u001B[1;32m    239\u001B[0m m \u001B[38;5;241m=\u001B[39m ImageMode\u001B[38;5;241m.\u001B[39mgetmode(im\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    240\u001B[0m shape \u001B[38;5;241m=\u001B[39m (im\u001B[38;5;241m.\u001B[39mheight, im\u001B[38;5;241m.\u001B[39mwidth)\n\u001B[0;32m--> 241\u001B[0m extra \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbands\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extra \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    243\u001B[0m     shape \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (extra,)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"[*] Training Epoch {epoch + 1}...\")\n",
    "    state, training_loss, training_accuracy = training_epoch(\n",
    "        state,\n",
    "        ds.trainloader,\n",
    "        forward,\n",
    "        ds.classification\n",
    "    )\n",
    "    print(f\"[*] Running Epoch {epoch + 1} Validation...\")\n",
    "    test_loss, test_accuracy = validation_epoch(\n",
    "        state,\n",
    "        ds.testloader,\n",
    "        forward,\n",
    "        ds.classification\n",
    "    )\n",
    "    print(f\"\\n=>> Epoch {epoch + 1} Metrics ===\")\n",
    "    print(\n",
    "        f\"\\tTrain Loss: {training_loss:.5f} -- Train Accuracy:\"\n",
    "        f\" {training_accuracy:.4f}\\n\\t Test Loss: {test_loss:.5f} --  Test\"\n",
    "        f\" Accuracy: {test_accuracy:.4f}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}